{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORE WLASL\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from moviepy.editor import VideoFileClip\n",
    "from pathlib import Path\n",
    "from WLASL.start_kit import preprocess\n",
    "from tqdm import tqdm\n",
    "\n",
    "JSON_FILE_PATH = \"WLASL/start_kit/WLASL_v0.3.json\"\n",
    "RAW_VIDEOS_PATH = Path(\"WLASL/start_kit/raw_videos\")\n",
    "SUBSET = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(JSON_FILE_PATH, 'r') as metadata_file:\n",
    "    annotations = json.load(metadata_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_path(video_id):\n",
    "    video_id = str(video_id)\n",
    "    for file in RAW_VIDEOS_PATH.iterdir():\n",
    "        if file.is_file() and file.stem == video_id:\n",
    "            return file\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting frame counts:   1%|          | 11/2000 [01:11<3:35:06,  6.49s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m tqdm(annotations, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGetting frame counts: \u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m      4\u001b[0m     \u001b[39mfor\u001b[39;00m instance \u001b[39min\u001b[39;00m word[\u001b[39m\"\u001b[39m\u001b[39minstances\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m----> 5\u001b[0m         video_path \u001b[39m=\u001b[39m get_video_path(instance[\u001b[39m\"\u001b[39;49m\u001b[39mvideo_id\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m      6\u001b[0m         \u001b[39mif\u001b[39;00m video_path:\n\u001b[1;32m      7\u001b[0m             \u001b[39mtry\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[60], line 3\u001b[0m, in \u001b[0;36mget_video_path\u001b[0;34m(video_id)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_video_path\u001b[39m(video_id):\n\u001b[1;32m      2\u001b[0m     video_id \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(video_id)\n\u001b[0;32m----> 3\u001b[0m     \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m RAW_VIDEOS_PATH\u001b[39m.\u001b[39miterdir():\n\u001b[1;32m      4\u001b[0m         \u001b[39mif\u001b[39;00m file\u001b[39m.\u001b[39mis_file() \u001b[39mand\u001b[39;00m file\u001b[39m.\u001b[39mstem \u001b[39m==\u001b[39m video_id:\n\u001b[1;32m      5\u001b[0m             \u001b[39mreturn\u001b[39;00m file\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/pathlib.py:1126\u001b[0m, in \u001b[0;36mPath.iterdir\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m..\u001b[39m\u001b[39m'\u001b[39m}:\n\u001b[1;32m   1124\u001b[0m     \u001b[39m# Yielding a path object for these makes little sense\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m-> 1126\u001b[0m \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_child_relpath(name)\n\u001b[1;32m   1127\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_closed:\n\u001b[1;32m   1128\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_closed()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/pathlib.py:1063\u001b[0m, in \u001b[0;36mPath._make_child_relpath\u001b[0;34m(self, part)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_make_child_relpath\u001b[39m(\u001b[39mself\u001b[39m, part):\n\u001b[1;32m   1060\u001b[0m     \u001b[39m# This is an optimization used for dir walking.  `part` must be\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m     \u001b[39m# a single part relative to this path.\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m     parts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parts \u001b[39m+\u001b[39m [part]\n\u001b[0;32m-> 1063\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_from_parsed_parts(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_drv, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_root, parts)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/pathlib.py:694\u001b[0m, in \u001b[0;36mPurePath._from_parsed_parts\u001b[0;34m(cls, drv, root, parts, init)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    692\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_from_parsed_parts\u001b[39m(\u001b[39mcls\u001b[39m, drv, root, parts, init\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    693\u001b[0m     \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__new__\u001b[39m(\u001b[39mcls\u001b[39m)\n\u001b[0;32m--> 694\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_drv \u001b[39m=\u001b[39m drv\n\u001b[1;32m    695\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_root \u001b[39m=\u001b[39m root\n\u001b[1;32m    696\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parts \u001b[39m=\u001b[39m parts\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "min = 90\n",
    "max = 0\n",
    "for word in tqdm(annotations, desc=\"Getting frame counts: \"):\n",
    "    for instance in word[\"instances\"]:\n",
    "        video_path = get_video_path(instance[\"video_id\"])\n",
    "        if video_path:\n",
    "            try:\n",
    "                FPS = VideoFileClip(str(video_path)).reader.nframes\n",
    "                min = min(min, FPS)\n",
    "                max = max(max, FPS)\n",
    "            except:\n",
    "                pass\n",
    "print(min, max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WLASL/start_kit/raw_videos/07069.mp4\n",
      "1280 720\n"
     ]
    }
   ],
   "source": [
    "#Draws bbox on video file - need instance from WLASL json file and a destination path\n",
    "def bbox_annotate(instance, destination_path=None):\n",
    "    if not destination_path:\n",
    "        default_dir = Path(\"test_videos\")\n",
    "        if not default_dir.is_dir():\n",
    "            default_dir.mkdir()\n",
    "\n",
    "        destination_path = Path(f\"test_videos/{instance['video_id']}_boxed.mp4\")\n",
    "    \n",
    "    raw_video_path = get_video_path(instance['video_id'])\n",
    "    frames = preprocess.extract_frame_as_video(str(raw_video_path), instance[\"frame_start\"], instance[\"frame_end\"]-1)\n",
    "\n",
    "    x, y, w, h = instance[\"bbox\"]\n",
    "    \n",
    "    for frame in frames:\n",
    "        cv2.rectangle(frame, (x, y), (w, h), color=(0, 255, 0), thickness=5)\n",
    "    \n",
    "    width, height = VideoFileClip(str(raw_video_path)).size\n",
    "    print(width, height)\n",
    "    bbox_video = preprocess.convert_frames_to_video(frames, destination_path, size=(width, height))\n",
    "\n",
    "\n",
    "bbox_annotate(annotations[0][\"instances\"][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WLASL/start_kit/raw_videos/43171.mp4\n",
      "(480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "def bbox_crop(instance, destination_path=None):\n",
    "    if not destination_path:\n",
    "        default_dir = Path(\"test_videos\")\n",
    "        if not default_dir.is_dir():\n",
    "            default_dir.mkdir()\n",
    "\n",
    "        destination_path = Path(f\"test_videos/{instance['video_id']}.mp4\")\n",
    "        \n",
    "    raw_video_path = get_video_path(instance['video_id'])\n",
    "    frames = preprocess.extract_frame_as_video(str(raw_video_path), instance[\"frame_start\"], instance[\"frame_end\"]-1)\n",
    "\n",
    "    x, y, w, h = instance[\"bbox\"]\n",
    "    width, height = VideoFileClip(str(raw_video_path)).size\n",
    "\n",
    "    padding_frame = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    print(padding_frame.shape)\n",
    "    \n",
    "    cropped_frames = []\n",
    "    for frame in frames:\n",
    "        cropped_frame = frame[y:h, x:w]\n",
    "        frame = np.copy(padding_frame)\n",
    "        \n",
    "        #Calculate Centering Coordinates\n",
    "        pad_x = max(0, (width - abs(x - w)) // 2)\n",
    "        pad_y = max(0, (height - abs(y - h)) // 2)\n",
    "\n",
    "        #Apply Crop\n",
    "        frame[pad_y:pad_y + abs(y - h), pad_x:pad_x + abs(x - w)] = cropped_frame\n",
    "\n",
    "        cropped_frames.append(frame)\n",
    "    \n",
    "    bbox_video = preprocess.convert_frames_to_video(cropped_frames, destination_path, size=(width, height))\n",
    "    \n",
    "\n",
    "# bbox_annotate(annotations[69][\"instances\"][5])\n",
    "bbox_crop(annotations[69][\"instances\"][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280 720\n"
     ]
    }
   ],
   "source": [
    "RAW_VIDEOS_PATH = Path(\"WLASL/start_kit/raw_videos_mp4\")\n",
    "YT_VID_PATH = RAW_VIDEOS_PATH / \"Kwvw-K6GYW8.mp4\"\n",
    "\n",
    "YT_VID_PATH = \"test_videos/output.mp4\"\n",
    "\n",
    "def bbox_annotate_yt(path, instance, destination_path=None):\n",
    "\n",
    "    if not destination_path:\n",
    "        default_dir = Path(\"test_videos\")\n",
    "        if not default_dir.is_dir():\n",
    "            default_dir.mkdir()\n",
    "\n",
    "        destination_path = Path(f\"test_videos/{instance['video_id']}.mp4\")\n",
    "\n",
    "    frames = preprocess.extract_frame_as_video(str(path), instance[\"frame_start\"], instance[\"frame_end\"]-1)\n",
    "\n",
    "    x, y, w, h = instance[\"bbox\"]\n",
    "\n",
    "    for frame in frames:\n",
    "        cv2.rectangle(frame, (x, y), (w, h), color=(0, 255, 0), thickness=5)\n",
    "\n",
    "    width, height = VideoFileClip(str(path)).size\n",
    "    print(width, height)\n",
    "    bbox_video = preprocess.convert_frames_to_video(frames, destination_path, size=(width, height))\n",
    "\n",
    "bbox_annotate_yt(YT_VID_PATH, annotations[0][\"instances\"][31])\n",
    "\n",
    "#ffmpeg -i WLASL/start_kit/raw_videos_mp4/Kwvw-K6GYW8.mp4 -vf scale=1280:720 test_videos/output.mp4\n",
    "\n",
    "#ffmpeg -i WLASL/start_kit/raw_videos_mp4/Kwvw-K6GYW8.mp4 -vf scale=1280:720 WLASL/start_kit/raw_videos_mp4/Kwvw-K6GYW8.mp4\n",
    "#ffmpeg -i WLASL/start_kit/raw_videos_mp4/XjWSfh50kAU.mp4 -vf scale=1280:720 WLASL/start_kit/raw_videos_mp4/XjWSfh50kAU_fixed.mp4\n",
    "#ffmpeg -i WLASL/start_kit/raw_videos_mp4/Kwvw-K6GYW8.mp4 -vf scale=1280:720 WLASL/start_kit/raw_videos_mp4/Kwvw-K6GYW8.mp4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "#BBox pretty good - create new video just using bbox border\n",
    "#Decide standardized frame and resolution - handle downsampling/upsampling\n",
    "#Create Processed dataset with \n",
    "#Create function to process videos by applying mediapipe to each frame and storing the resulting file in processed folder\n",
    "\n",
    "\"\"\"\n",
    "Process function\n",
    "    1. Set location of 30 frame video to test, train, val (Create folder for word if doesn't exist)\n",
    "    2. check url/id\n",
    "        - if YT in url, search for YT video download by YT id\n",
    "        - if id, search for number id\n",
    "    3. Video exists?\n",
    "        - if not move on\n",
    "        - if so, name video after id\n",
    "    4. Reduce/Increase video to 30 frames\n",
    "    5. Apply Bbox crop to each video\n",
    "    6. Save Video\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ms-asl-env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10 (v3.8.10:3d8993a744, May  3 2021, 09:09:08) \n[Clang 12.0.5 (clang-1205.0.22.9)]"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
