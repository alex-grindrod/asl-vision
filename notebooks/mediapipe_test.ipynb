{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ajaxcarroway/Desktop/My Stuff/Personal Projects/ASL_Demo/asl_model/notebooks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724024959.704474 20680625 gl_context.cc:357] GL version: 2.1 (2.1 ATI-5.5.17), renderer: AMD Radeon Pro 560X OpenGL Engine\n"
     ]
    }
   ],
   "source": [
    "from src.mp_annotate import mp_demo, get_datapoints, draw_datapoints, draw_datapoints_from_tensors, annotate_video\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(744,)\n",
      "(30, 744)\n"
     ]
    }
   ],
   "source": [
    "data = annotate_video(\"../data/processed_unsplit_30/adopt/01160.mp4\", save_video_path=\"../test_videos/01160_annotated.mp4\")\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results, image = mp_demo(stop_frame=10)\n",
    "# org_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "# plt.imshow(org_image)\n",
    "# plt.axis('off')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = copy.deepcopy(org_image)\n",
    "# face, left, pose, right = get_datapoints(results)\n",
    "# image = draw_datapoints_from_tensors([face, left, pose, right], image)\n",
    "\n",
    "# plt.imshow(image)\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(results\u001b[39m.\u001b[39mpose_landmarks))\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(results\u001b[39m.\u001b[39mright_hand_landmarks))\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(results\u001b[39m.\u001b[39mleft_hand_landmarks))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "print(type(results.pose_landmarks))\n",
    "print(type(results.right_hand_landmarks))\n",
    "print(type(results.left_hand_landmarks))\n",
    "print(type(results.face_landmarks))\n",
    "\n",
    "pose = np.array([[p.x, p.y, p.z, p.visibility] for p in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(132)\n",
    "right = np.array([[p.x, p.y, p.z] for p in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(63)\n",
    "left = np.array([[p.x, p.y, p.z] for p in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(63)\n",
    "face = np.array([[p.x, p.y, p.z] for p in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(1404)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'org_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m image \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(org_image)\n\u001b[1;32m      3\u001b[0m \u001b[39m# image = draw_datapoints(results.face_landmarks, [70, 63, 105, 66, 107, 46, 53, 52, 65, 55], image) #left eyebrow\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# image = draw_datapoints(results.face_landmarks, [336, 296, 334, 293, 300, 285, 295, 282, 283, 276], image) #right eyebrow\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m \u001b[39m# image = draw_datapoints(results.pose_landmarks, [11, 12, 13, 14, 15, 16], image) #wrist, elbow, shoulder\u001b[39;00m\n\u001b[1;32m     24\u001b[0m plt\u001b[39m.\u001b[39mimshow(image)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'org_image' is not defined"
     ]
    }
   ],
   "source": [
    "image = copy.deepcopy(org_image)\n",
    "\n",
    "# image = draw_datapoints(results.face_landmarks, [70, 63, 105, 66, 107, 46, 53, 52, 65, 55], image) #left eyebrow\n",
    "# image = draw_datapoints(results.face_landmarks, [336, 296, 334, 293, 300, 285, 295, 282, 283, 276], image) #right eyebrow\n",
    "\n",
    "# image = draw_datapoints(results.face_landmarks, [146, 77, 96, 95, 91, 90, 89, 88, 181, 180, 179, 178, 87, 86, 85, 84, \n",
    "#                                                  14, 15, 16, 17, 317, 316, 315, 314, 402, 403, 404, 405, 318, 319, 320, 321,\n",
    "#                                                  324, 325, 307, 375, 306, 292, 62, 78], image) #bottom lip\n",
    "# image = draw_datapoints(results.face_landmarks, [61, 76, 185, 184, 183, 191, 40, 74, 42, 80, 39, 73, 41, 81, 37, 72, \n",
    "#                                                  38, 82, 0, 11, 12, 13, 267, 302, 268, 312, 269, 303, 271, 311, 270, 304, 272, 310,\n",
    "#                                                  409, 408, 407, 415, 291, 308], image) #top lip\n",
    "\n",
    "# image = draw_datapoints(results.face_landmarks, [10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 401, 361, 435, 288,\n",
    "#                                                  397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 136, 172, 58, \n",
    "#                                                  132, 93, 234, 127, 162, 21, 54, 103, 67, 109], image) #face outline\n",
    "\n",
    "# image = draw_datapoints(results.right_hand_landmarks, [i for i in range(21)], image) #right hand\n",
    "# image = draw_datapoints(results.left_hand_landmarks, [i for i in range(21)], image) #left hand\n",
    "\n",
    "# image = draw_datapoints(results.pose_landmarks, [11, 12, 13, 14, 15, 16], image) #wrist, elbow, shoulder\n",
    "\n",
    "\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ms-asl-env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "056b1385d818fc0f0029bac8298484af6027bd9d3da6d90f1a42e3bfc51717ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
